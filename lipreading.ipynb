{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6ed107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.installing and importing dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1e1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- --------------------\n",
      "absl-py                       1.4.0\n",
      "alabaster                     0.7.12\n",
      "altair                        5.0.1\n",
      "anaconda-client               1.11.0\n",
      "anaconda-navigator            2.3.2\n",
      "anaconda-project              0.11.1\n",
      "anyio                         3.5.0\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "arrow                         1.2.2\n",
      "astroid                       2.11.7\n",
      "astropy                       5.1\n",
      "astunparse                    1.6.3\n",
      "atomicwrites                  1.4.0\n",
      "attrs                         21.4.0\n",
      "Automat                       20.2.0\n",
      "autopep8                      1.6.0\n",
      "Babel                         2.9.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "backports.tempfile            1.0\n",
      "backports.weakref             1.0.post1\n",
      "bcrypt                        3.2.0\n",
      "beautifulsoup4                4.11.1\n",
      "binaryornot                   0.4.4\n",
      "bitarray                      2.5.1\n",
      "bkcharts                      0.2\n",
      "black                         22.6.0\n",
      "bleach                        4.1.0\n",
      "blinker                       1.6.2\n",
      "blis                          0.7.10\n",
      "bokeh                         2.4.3\n",
      "boto3                         1.24.28\n",
      "botocore                      1.27.28\n",
      "Bottleneck                    1.3.5\n",
      "brotlipy                      0.7.0\n",
      "cachetools                    5.3.1\n",
      "catalogue                     2.0.9\n",
      "certifi                       2022.9.14\n",
      "cffi                          1.15.1\n",
      "chardet                       4.0.0\n",
      "charset-normalizer            2.0.4\n",
      "click                         8.0.4\n",
      "cloudpickle                   2.0.0\n",
      "clusteval                     2.1.5\n",
      "clyent                        1.2.2\n",
      "colorama                      0.4.6\n",
      "colorcet                      3.0.0\n",
      "comtypes                      1.1.10\n",
      "conda                         23.1.0\n",
      "conda-build                   3.22.0\n",
      "conda-content-trust           0.1.3\n",
      "conda-pack                    0.6.0\n",
      "conda-package-handling        1.9.0\n",
      "conda-repo-cli                1.0.20\n",
      "conda-token                   0.4.0\n",
      "conda-verify                  3.4.2\n",
      "confection                    0.1.0\n",
      "constantly                    15.1.0\n",
      "cookiecutter                  1.7.3\n",
      "cryptography                  37.0.1\n",
      "cssselect                     1.1.0\n",
      "cycler                        0.11.0\n",
      "cymem                         2.0.7\n",
      "Cython                        0.29.32\n",
      "cytoolz                       0.11.0\n",
      "daal4py                       2021.6.0\n",
      "dask                          2022.7.0\n",
      "datashader                    0.14.1\n",
      "datashape                     0.5.4\n",
      "debugpy                       1.5.1\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "diff-match-patch              20200713\n",
      "dill                          0.3.4\n",
      "distributed                   2022.7.0\n",
      "docutils                      0.18.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "fastjsonschema                2.16.2\n",
      "feature-engine                1.5.2\n",
      "filelock                      3.6.0\n",
      "flake8                        4.0.1\n",
      "Flask                         1.1.2\n",
      "flatbuffers                   23.5.26\n",
      "fonttools                     4.25.0\n",
      "fsspec                        2022.7.1\n",
      "future                        0.18.2\n",
      "gast                          0.4.0\n",
      "gdown                         4.7.1\n",
      "gensim                        4.1.2\n",
      "gitdb                         4.0.10\n",
      "GitPython                     3.1.32\n",
      "glob2                         0.7\n",
      "google-auth                   2.23.0\n",
      "google-auth-oauthlib          1.0.0\n",
      "google-pasta                  0.2.0\n",
      "greenlet                      1.1.1\n",
      "grpcio                        1.58.0\n",
      "h5py                          3.7.0\n",
      "HeapDict                      1.0.1\n",
      "holoviews                     1.15.0\n",
      "hvplot                        0.8.0\n",
      "hyperlink                     21.0.0\n",
      "idna                          3.3\n",
      "imagecodecs                   2021.8.26\n",
      "imageio                       2.19.3\n",
      "imagesize                     1.4.1\n",
      "importlib-metadata            4.11.3\n",
      "importlib-resources           5.12.0\n",
      "incremental                   21.3.0\n",
      "inflection                    0.5.1\n",
      "iniconfig                     1.1.1\n",
      "intake                        0.6.5\n",
      "intervaltree                  3.1.0\n",
      "ipykernel                     6.15.2\n",
      "ipython                       7.31.1\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    7.6.5\n",
      "isort                         5.9.3\n",
      "itemadapter                   0.3.0\n",
      "itemloaders                   1.0.4\n",
      "itsdangerous                  2.0.1\n",
      "jdcal                         1.4.1\n",
      "jedi                          0.18.1\n",
      "jellyfish                     0.9.0\n",
      "Jinja2                        2.11.3\n",
      "jinja2-time                   0.2.0\n",
      "jmespath                      0.10.0\n",
      "joblib                        1.1.0\n",
      "json5                         0.9.6\n",
      "jsonschema                    4.16.0\n",
      "jupyter                       1.0.0\n",
      "jupyter_client                7.3.4\n",
      "jupyter-console               6.4.3\n",
      "jupyter_core                  4.11.1\n",
      "jupyter-server                1.18.1\n",
      "jupyterlab                    3.4.4\n",
      "jupyterlab-pygments           0.1.2\n",
      "jupyterlab-server             2.10.3\n",
      "jupyterlab-widgets            1.0.0\n",
      "keras                         2.13.1\n",
      "keyring                       23.4.0\n",
      "kiwisolver                    1.4.2\n",
      "langcodes                     3.3.0\n",
      "lazy-object-proxy             1.6.0\n",
      "libarchive-c                  2.9\n",
      "libclang                      16.0.6\n",
      "lightgbm                      4.0.0\n",
      "llvmlite                      0.38.0\n",
      "locket                        1.0.0\n",
      "loguru                        0.6.0\n",
      "lxml                          4.9.1\n",
      "lz4                           3.1.3\n",
      "Markdown                      3.3.4\n",
      "markdown-it-py                3.0.0\n",
      "MarkupSafe                    2.0.1\n",
      "matplotlib                    3.5.2\n",
      "matplotlib-inline             0.1.6\n",
      "mccabe                        0.6.1\n",
      "mdurl                         0.1.2\n",
      "menuinst                      1.4.19\n",
      "mistune                       0.8.4\n",
      "mkl-fft                       1.3.1\n",
      "mkl-random                    1.2.2\n",
      "mkl-service                   2.4.0\n",
      "mock                          4.0.3\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.3\n",
      "multipledispatch              0.6.0\n",
      "munkres                       1.1.4\n",
      "murmurhash                    1.0.9\n",
      "mypy-extensions               0.4.3\n",
      "navigator-updater             0.3.0\n",
      "nbclassic                     0.3.5\n",
      "nbclient                      0.5.13\n",
      "nbconvert                     6.4.4\n",
      "nbformat                      5.5.0\n",
      "nest-asyncio                  1.5.5\n",
      "networkx                      2.8.4\n",
      "nltk                          3.7\n",
      "nose                          1.3.7\n",
      "notebook                      6.4.12\n",
      "numba                         0.55.1\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.24.3\n",
      "numpydoc                      1.4.0\n",
      "oauthlib                      3.2.2\n",
      "olefile                       0.46\n",
      "opencv-python                 4.8.0.76\n",
      "openpyxl                      3.0.10\n",
      "opt-einsum                    3.3.0\n",
      "packaging                     21.3\n",
      "pandas                        1.4.4\n",
      "pandocfilters                 1.5.0\n",
      "panel                         0.13.1\n",
      "param                         1.12.0\n",
      "paramiko                      2.8.1\n",
      "parsel                        1.6.0\n",
      "parso                         0.8.3\n",
      "partd                         1.2.0\n",
      "pathlib                       1.0.1\n",
      "pathspec                      0.9.0\n",
      "pathy                         0.10.2\n",
      "patsy                         0.5.2\n",
      "pep8                          1.7.1\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.2.0\n",
      "pip                           22.2.2\n",
      "pkginfo                       1.8.2\n",
      "platformdirs                  2.5.2\n",
      "plotly                        5.9.0\n",
      "pluggy                        1.0.0\n",
      "pmdarima                      2.0.3\n",
      "poyo                          0.5.0\n",
      "preshed                       3.0.8\n",
      "prometheus-client             0.14.1\n",
      "prompt-toolkit                3.0.20\n",
      "Protego                       0.1.16\n",
      "protobuf                      4.24.1\n",
      "psutil                        5.9.0\n",
      "psycopg2                      2.9.7\n",
      "ptyprocess                    0.7.0\n",
      "py                            1.11.0\n",
      "py-AutoClean                  1.1.3\n",
      "pyarrow                       13.0.0\n",
      "pyasn1                        0.4.8\n",
      "pyasn1-modules                0.2.8\n",
      "pycodestyle                   2.8.0\n",
      "pycosat                       0.6.3\n",
      "pycparser                     2.21\n",
      "pyct                          0.4.8\n",
      "pycurl                        7.45.1\n",
      "pydantic                      1.10.12\n",
      "pydeck                        0.8.0\n",
      "PyDispatcher                  2.0.5\n",
      "pydocstyle                    6.1.1\n",
      "pyerfa                        2.0.0\n",
      "pyflakes                      2.4.0\n",
      "Pygments                      2.16.1\n",
      "PyHamcrest                    2.0.2\n",
      "PyJWT                         2.4.0\n",
      "pylint                        2.14.5\n",
      "pyls-spyder                   0.4.0\n",
      "Pympler                       1.0.1\n",
      "PyMySQL                       1.0.3\n",
      "PyNaCl                        1.5.0\n",
      "pyodbc                        4.0.34\n",
      "pyOpenSSL                     22.0.0\n",
      "pyparsing                     3.0.9\n",
      "pypickle                      1.1.0\n",
      "pyrsistent                    0.18.0\n",
      "PySocks                       1.7.1\n",
      "pytest                        7.1.2\n",
      "python-dateutil               2.8.2\n",
      "python-lsp-black              1.0.0\n",
      "python-lsp-jsonrpc            1.0.0\n",
      "python-lsp-server             1.3.3\n",
      "python-slugify                5.0.2\n",
      "python-snappy                 0.6.0\n",
      "pytz                          2022.1\n",
      "pytz-deprecation-shim         0.1.0.post0\n",
      "pyviz-comms                   2.0.2\n",
      "PyWavelets                    1.3.0\n",
      "pywin32                       302\n",
      "pywin32-ctypes                0.2.0\n",
      "pywinpty                      2.0.2\n",
      "PyYAML                        6.0\n",
      "pyzmq                         23.2.0\n",
      "QDarkStyle                    3.0.2\n",
      "qstylizer                     0.1.10\n",
      "QtAwesome                     1.0.3\n",
      "qtconsole                     5.2.2\n",
      "QtPy                          2.2.0\n",
      "queuelib                      1.5.0\n",
      "regex                         2022.7.9\n",
      "requests                      2.28.1\n",
      "requests-file                 1.5.1\n",
      "requests-oauthlib             1.3.1\n",
      "rich                          13.5.2\n",
      "rope                          0.22.0\n",
      "rsa                           4.9\n",
      "Rtree                         0.9.7\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.6\n",
      "ruamel-yaml-conda             0.15.100\n",
      "s3transfer                    0.6.0\n",
      "scikit-image                  0.19.2\n",
      "scikit-learn                  1.0.2\n",
      "scikit-learn-intelex          2021.20221004.171935\n",
      "scipy                         1.9.1\n",
      "Scrapy                        2.6.2\n",
      "seaborn                       0.11.2\n",
      "Send2Trash                    1.8.0\n",
      "service-identity              18.1.0\n",
      "setuptools                    63.4.1\n",
      "sip                           4.19.13\n",
      "six                           1.16.0\n",
      "smart-open                    5.2.1\n",
      "smmap                         5.0.0\n",
      "sniffio                       1.2.0\n",
      "snowballstemmer               2.2.0\n",
      "sortedcollections             2.1.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.1\n",
      "spacy                         3.6.0\n",
      "spacy-legacy                  3.0.12\n",
      "spacy-loggers                 1.0.4\n",
      "Sphinx                        5.0.2\n",
      "sphinxcontrib-applehelp       1.0.2\n",
      "sphinxcontrib-devhelp         1.0.2\n",
      "sphinxcontrib-htmlhelp        2.0.0\n",
      "sphinxcontrib-jsmath          1.0.1\n",
      "sphinxcontrib-qthelp          1.0.3\n",
      "sphinxcontrib-serializinghtml 1.1.5\n",
      "spyder                        5.2.2\n",
      "spyder-kernels                2.2.1\n",
      "SQLAlchemy                    1.4.39\n",
      "srsly                         2.4.7\n",
      "statsmodels                   0.13.2\n",
      "streamlit                     1.26.0\n",
      "sweetviz                      2.1.4\n",
      "sympy                         1.10.1\n",
      "tables                        3.6.1\n",
      "tabulate                      0.8.10\n",
      "TBB                           0.2\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.3\n",
      "tensorboard                   2.13.0\n",
      "tensorboard-data-server       0.7.1\n",
      "tensorflow                    2.13.0\n",
      "tensorflow-estimator          2.13.0\n",
      "tensorflow-intel              2.13.0\n",
      "tensorflow-io-gcs-filesystem  0.31.0\n",
      "termcolor                     2.3.0\n",
      "terminado                     0.13.1\n",
      "testpath                      0.6.0\n",
      "text-unidecode                1.3\n",
      "textdistance                  4.2.1\n",
      "thinc                         8.1.10\n",
      "threadpoolctl                 2.2.0\n",
      "three-merge                   0.1.1\n",
      "tifffile                      2021.7.2\n",
      "tinycss                       0.4\n",
      "tldextract                    3.2.0\n",
      "toml                          0.10.2\n",
      "tomli                         2.0.1\n",
      "tomlkit                       0.11.1\n",
      "toolz                         0.11.2\n",
      "tornado                       6.1\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.1.1\n",
      "Twisted                       22.2.0\n",
      "twisted-iocpsupport           1.0.2\n",
      "typer                         0.9.0\n",
      "typing_extensions             4.3.0\n",
      "tzdata                        2023.3\n",
      "tzlocal                       4.3.1\n",
      "ujson                         5.4.0\n",
      "Unidecode                     1.2.0\n",
      "urllib3                       1.26.11\n",
      "validators                    0.21.2\n",
      "w3lib                         1.21.0\n",
      "wasabi                        1.1.2\n",
      "watchdog                      2.1.6\n",
      "wcwidth                       0.2.5\n",
      "webencodings                  0.5.1\n",
      "websocket-client              0.58.0\n",
      "Werkzeug                      2.0.3\n",
      "wget                          3.2\n",
      "wheel                         0.37.1\n",
      "widgetsnbextension            3.5.2\n",
      "win-inet-pton                 1.1.0\n",
      "win-unicode-console           0.5\n",
      "win32-setctime                1.1.0\n",
      "wincertstore                  0.2\n",
      "wrapt                         1.14.1\n",
      "xarray                        0.20.1\n",
      "xgboost                       1.7.6\n",
      "xlrd                          2.0.1\n",
      "XlsxWriter                    3.0.3\n",
      "xlwings                       0.27.15\n",
      "yapf                          0.31.0\n",
      "zict                          2.1.0\n",
      "zipp                          3.8.0\n",
      "zope.interface                5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed5229d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script google-oauthlib-tool.exe is installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script gdown.exe is installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\ANURAJ B N\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "     ---------------------------------------- 38.1/38.1 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: imageio in c:\\programdata\\anaconda3\\lib\\site-packages (2.19.3)\n",
      "Collecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (3.6.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Collecting tensorflow-intel==2.13.0\n",
      "  Using cached tensorflow_intel-2.13.0-cp39-cp39-win_amd64.whl (276.5 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 5.7 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (63.4.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.58.0-cp39-cp39-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\anuraj b n\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 7.3 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.8/440.8 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     ---------------------------------------- 14.9/14.9 MB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anuraj b n\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->gdown) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.4/181.4 kB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\anuraj b n\\appdata\\roaming\\python\\python39\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, oauthlib, numpy, keras, grpcio, google-pasta, gast, astunparse, absl-py, requests-oauthlib, opt-einsum, opencv-python, google-auth, google-auth-oauthlib, gdown, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 flatbuffers-23.5.26 gast-0.4.0 gdown-4.7.1 google-auth-2.23.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.58.0 keras-2.13.1 libclang-16.0.6 numpy-1.24.3 oauthlib-3.2.2 opencv-python-4.8.0.76 opt-einsum-3.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python matplotlib imageio gdown tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28a1df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e9b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os: For file system operations.\n",
    "#cv2: For computer vision and image manipulation.\n",
    "#tensorflow (or tf): For machine learning and deep learning.\n",
    "#numpy (or np): For numerical data manipulation.\n",
    "#typing.List: For specifying function argument types.\n",
    "#matplotlib.pyplot: For creating visualizations.\n",
    "#imageio: For reading and writing image and video formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61d56ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cec69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bcf71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Build data loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413d5a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f933ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://drive.google.com/uc?id=1Y1vDLix35-U8fd-gqwRcWXAXm8JwjL'\n",
    "output = 'data.zip'\n",
    "gdown.download(url,output,quiet=False)\n",
    "gdown.extractall('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f75f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code downloads a file from a Google Drive URL using the gdown library, saves it as 'data.zip', and then extracts its contents into the current working directory using the zipfile library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec12aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.data loading function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str)->list[float]:\n",
    "    \n",
    "    cap = cv2.videoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret,frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236:,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames,tf,float32))\n",
    "    return tf.cast((frames - mean),tf.float32)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes a video file path, loads the video, processes its frames by converting them to grayscale and cropping a specific region, calculates statistical values (mean and standard deviation) for the frames, and returns the frames as a list of floating-point numbers that have been normalized with zero mean and scaled by the standard deviation, making them suitable for further analysis or machine learning tasks.\n",
    "#(frame[190:236:,80:220,:]) It appends a cropped version of the frame (the lip part)) to the frames list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvxyz'?!123456789\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b819c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\", mask_token=\"\", invert=True)\n",
    "\n",
    "print(f\"The vocabulary is: {char_to_num.get_vocabulary()} (size = {char_to_num.vocabulary_size()})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, the code initializes two layers for character-to-number and number-to-character mappings, and it prints out information about the vocabulary size and the actual vocabulary list\n",
    "#hese layers are a crucial part of text preprocessing in NLP tasks, enabling the conversion between text and numerical representations while providing flexibility to handle out-of-vocabulary tokens. The printed vocabulary information is helpful for understanding the characteristics of your text data and configuring your models accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def load_alignments(path: str, char_to_num) -> List[str]:\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil':\n",
    "            tokens.extend([' ', line[2]])\n",
    "    \n",
    "    \n",
    "    indices = char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]\n",
    "    \n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdf570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It opens a file you specify (with a path) and reads what's inside.\n",
    "#It looks at each line in the file and breaks it into smaller pieces (like words).\n",
    "#If a certain condition is met (in this case, if the third piece is not the word \"sil\"), it keeps track of those pieces.\n",
    "#It takes those pieces and turns them into numbers (imagine turning letters into numbers in a secret code).\n",
    "#It gives you the list of numbers it found.\n",
    "#This code could be used for things like turning spoken words into a series of numbers that a computer can understand or aligning words in a transcription to words in an audio recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path:str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.aligmnet)'\n",
    "    frames = load_video(video_path)\n",
    "    alignment = load_alignment(alignment_path)\n",
    "    \n",
    "    return frames,alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is designed to prepare and retrieve data related to video frames and alignment, using a provided path and other assumptions about the directory structure and data sources. It's important to ensure that the necessary functions (load_video and load_alignment) and data sources (alignment_path) are correctly defined and set up in your code for this function to work as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b869805",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = ',\\\\data\\\\s1\\\\bba16n.mpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(test_path).numpy().decode(utf-8).split('\\\\')[-1].spilt(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b391e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code takes a test path, processes it to obtain path components, and then loads data using the load_data function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a66a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames,alignments=load_data(tf.convert_to_tensor(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe66ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str)-.List[str]:\n",
    "    result = tf.py_function(load_data,[path],(tf.float32,tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mappable_function takes a path as input, applies the load_data function to it as a TensorFlow computation, and returns the result as a tuple of a float tensor and an integer tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584476a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Create Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f451f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_pattern = '/data/s1/*.mpg'\n",
    "file_paths = tf.data.Dataset.list_files(file_pattern)\n",
    "data = file_paths.shuffle(500)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75, None, None, None]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In summary, this code sets up a data pipeline that loads and preprocesses video data from files, shuffles the data for randomness, batches it with padding for model input, and prefetches data for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3598ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Design the Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83dcd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os: This statement imports the os module, which is used for interacting with the operating system, allowing you to work with files, directories, and paths.\n",
    "#import tensorflow as tf: This imports the TensorFlow library, a popular deep learning framework used for building and training neural networks.\n",
    "#from tensorflow.keras.models import Sequential: It imports the Sequential class, which is a Keras feature used to create a linear stack of neural network layers.\n",
    "#from tensorflow.keras.layers import ...: These lines import various layer types and components from Keras, which are building blocks for constructing neural networks. Some notable components include convolutional layers (Conv3D), recurrent layers (LSTM), fully connected layers (Dense), dropout layers (Dropout), bidirectional layers (Bidirectional), pooling layers (MaxPool3D), activation functions (Activation), reshaping layers (Reshape), dropout layers for 3D data (SpatialDropout3D), batch normalization layers (BatchNormalization), and time-distributed layers (TimeDistributed).\n",
    "#from tensorflow.keras.optimizers import Adam: This line imports the Adam optimizer, a widely used optimization algorithm for training neural networks.\n",
    "#from tensorflow.keras.callbacks import ...: These lines import various callback functions provided by Keras for enhancing the training process. Notable callbacks include ModelCheckpoint for saving model checkpoints during training and LearningRateScheduler for adjusting learning rates during training based on a predefined schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8f8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(128, 3, input_shape=(75, 46, 140, 1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D(pool_size=(1, 2, 2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size() + 1, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6704ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is defined as a Sequential model, which means that layers are added sequentially.\n",
    "#Convolutional layers (Conv3D) are added with ReLU activations and max-pooling layers.\n",
    "#The TimeDistributed layer is used to apply the Flatten operation to the output of the convolutional layers, making it compatible with the LSTM layers.\n",
    "#Bidirectional LSTM layers are added with dropout to improve model performance and reduce overfitting.\n",
    "#Finally, a Dense output layer is added with a softmax activation function to produce the model's predictions.\n",
    "#The model is compiled with an Adam optimizer and sparse categorical cross-entropy loss ( it's a classification task). Also, accuracy is monitored as a metric.\n",
    "#A summary of the model's architecture is printed to provide an overview of the layer shapes and the total number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6198f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provides a summary of your neural network model, including information about the layers, the number of trainable parameters, and the output shapes at each layer. This summary is incredibly useful for understanding the architecture of your model and diagnosing potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Set up and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d786fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch<30:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr *tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In summary, this scheduler function keeps the learning rate constant for the first 30 epochs and then applies an exponential decay to reduce the learning rate as training continues. Learning rate scheduling is a technique used to improve the convergence and stability of training deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6808e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true,y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0],dtype=\"int64\")\n",
    "    input_lenght = tf.cast(tf.shape(y_pred)[1],dtype=\"int64\")\n",
    "    label_lenght = tf.cast(tf.shape(y_true)[1],dtype=\"int64\")\n",
    "    \n",
    "    input_lengh = input_lengh * tf.ones(shape=(batch_len,1),dtype=\"int64\")\n",
    "    label_lengh = label_lengh *tf.ones(shape =(batch_len,1),dtype=\"int64\")\n",
    "    \n",
    "    loss= tf.keras.backend.ctc_batch_cost(y_true,y_pred,input_lengh,label_lengh)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60596624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This custom CTC loss function can be used as the loss function in a Keras model for training tasks that involve sequence-to-sequence mapping, where aligning input and target sequences can be challenging. CTC loss helps the model learn to make predictions while handling variable-length input sequences and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8bee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProduceExample(tf.keras.callbacks.Callback): \n",
    "    def __init__(self, dataset) -> None: \n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None) -> None:\n",
    "        data = self.dataset.next()\n",
    "        yhat = self.model.predict(data[0])\n",
    "        decoded = tf.keras.backend.ctc_decode(yhat, [75,75], greedy=False)[0][0].numpy()\n",
    "        for x in range(len(yhat)):           \n",
    "            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))\n",
    "            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))\n",
    "            print('~'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c8ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This callback provides a way to visually inspect and compare the model's predictions with the actual ground truth labels at the end of each training epoch. It is particularly useful for tasks involving sequence data, such as text recognition or speech recognition, to track the model's performance and identify any issues or improvements during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b34c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ff668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to use the Adam optimizer with a specific learning rate and to minimize the CTC loss during training. When you call model.fit() to train the model later on, it will use these settings for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f306533",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(os.path.join('models','checkpoint'), monitor='loss', save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2920c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelCheckpoint callback is a valuable tool for managing and monitoring the training of machine learning models, allowing you to save model states at key points during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_callback = LearningRateScheduler(scheduler)\n",
    "example_callback = ProduceExample(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05eb522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These callbacks enhance your training process by providing mechanisms for fine-tuning the learning rate and for monitoring and visualizing model predictions, making it easier to understand and improve the performance of your machine learning model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train, validation_data=test, epochs=100, callbacks=[checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model.fit call trains your model on the train dataset, evaluates it on the test dataset, and applies the specified callbacks to optimize and monitor the training process over 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465de9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "output = 'checkpoints.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "gdown.extractall('checkpoints.zip', 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d482c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()\n",
    "sample = test_data.next()\n",
    "yhat = model.predict(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e3ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'REAL TEXT')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf449dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('~'*100, 'PREDICTIONS')\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e62fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e3178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce262c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e014eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769f410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8d20e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
